{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to import the code \n",
    "import sys\n",
    "sys.path.insert(0, '/ibmm_data/TemBERTure/model/code/') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Models loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/BERTSequential/2_LAYERS_HEAD/PARTIAL_EPOCH_CLS_WEIGHTS/0_25',\n",
       " '/BERTSequential/2_LAYERS_HEAD/PARTIAL_EPOCH_CLS_WEIGHTS/0_50',\n",
       " '/BERTSequential/2_LAYERS_HEAD/PARTIAL_EPOCH_CLS_WEIGHTS/0_75',\n",
       " '/BERTSequential/2_LAYERS_HEAD/PARTIAL_EPOCH_CLS_WEIGHTS/1/1E-3',\n",
       " '/BERTSequential/2_LAYERS_HEAD/FULL_CLS_TRAINING',\n",
       " '/BERT_regr/2_LAYER_HEAD']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Paths Setup: It defines main_path as the root directory for the data and partial_epoch_path as a subdirectory.\n",
    "main_path = '/ibmm_data/TemBERTure/model'\n",
    "partial_epoch_path ='/BERTSequential/2_LAYERS_HEAD/PARTIAL_EPOCH_CLS_WEIGHTS/'\n",
    "full_cls_epoch_path = '/BERTSequential/2_LAYERS_HEAD/FULL_CLS_TRAINING'\n",
    "random_individual_path = '/BERT_regr/2_LAYER_HEAD'\n",
    "\n",
    "# Categories: Lists of category names (categories) and composed paths (categories_path) are set.\n",
    "## *** KEEP THE SAME ORDER BETWEEN categories AND categories_path TO MAKE THE PATH READER WORKING LATER ***\n",
    "categories = ['0_25', '0_50', '0_75', '1/1E-3','FULL_CLS','RANDOM']\n",
    "# composed path for each category\n",
    "categories_path=[f'{partial_epoch_path}0_25',f'{partial_epoch_path}0_50',f'{partial_epoch_path}0_75',f'{partial_epoch_path}1/1E-3',f'{full_cls_epoch_path}',f'{random_individual_path}']\n",
    "categories_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ibmm_data/TemBERTure/model/BERTSequential/2_LAYERS_HEAD/PARTIAL_EPOCH_CLS_WEIGHTS/0_25/3_REPLICAS/025_CLS_lr1e-3_headdrop0.3_replica1/output/checkpoint-73320_epoch39_best_model/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at Rostlab/prot_bert_bfd were not used when initializing BertAdapterModel: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertAdapterModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertAdapterModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ibmm_data/TemBERTure/model/BERTSequential/2_LAYERS_HEAD/PARTIAL_EPOCH_CLS_WEIGHTS/0_25/3_REPLICAS/025_CLS_lr1e-3_headdrop0.3_replica2/output/checkpoint-7520_epoch4_best_model/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at Rostlab/prot_bert_bfd were not used when initializing BertAdapterModel: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertAdapterModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertAdapterModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ibmm_data/TemBERTure/model/BERTSequential/2_LAYERS_HEAD/PARTIAL_EPOCH_CLS_WEIGHTS/0_25/3_REPLICAS/025_CLS_lr1e-3_headdrop0.3_replica3/output/checkpoint-31960_epoch17_best_model/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at Rostlab/prot_bert_bfd were not used when initializing BertAdapterModel: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertAdapterModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertAdapterModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ibmm_data/TemBERTure/model/BERTSequential/2_LAYERS_HEAD/PARTIAL_EPOCH_CLS_WEIGHTS/0_50/3_REPLICAS/050_CLS_lr1e-3_headdrop0.3_replica1/output/checkpoint-60160_epoch32_best_model/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at Rostlab/prot_bert_bfd were not used when initializing BertAdapterModel: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertAdapterModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertAdapterModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ibmm_data/TemBERTure/model/BERTSequential/2_LAYERS_HEAD/PARTIAL_EPOCH_CLS_WEIGHTS/0_50/3_REPLICAS/050_CLS_lr1e-3_headdrop0.3_replica2/output/checkpoint-60160_epoch32_best_model/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at Rostlab/prot_bert_bfd were not used when initializing BertAdapterModel: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertAdapterModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertAdapterModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ibmm_data/TemBERTure/model/BERTSequential/2_LAYERS_HEAD/PARTIAL_EPOCH_CLS_WEIGHTS/0_50/3_REPLICAS/050_CLS_lr1e-3_headdrop0.3_replica3/output/checkpoint-13160_epoch7_best_model/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at Rostlab/prot_bert_bfd were not used when initializing BertAdapterModel: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertAdapterModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertAdapterModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ibmm_data/TemBERTure/model/BERTSequential/2_LAYERS_HEAD/PARTIAL_EPOCH_CLS_WEIGHTS/0_75/3_REPLICAS/075_CLS_lr1e-3_headdrop0.3_replica1/output/checkpoint-3760_epoch2_best_model/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at Rostlab/prot_bert_bfd were not used when initializing BertAdapterModel: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertAdapterModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertAdapterModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ibmm_data/TemBERTure/model/BERTSequential/2_LAYERS_HEAD/PARTIAL_EPOCH_CLS_WEIGHTS/0_75/3_REPLICAS/075_CLS_lr1e-3_headdrop0.3_replica2/output/checkpoint-73320_epoch39_best_model/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at Rostlab/prot_bert_bfd were not used when initializing BertAdapterModel: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertAdapterModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertAdapterModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ibmm_data/TemBERTure/model/BERTSequential/2_LAYERS_HEAD/PARTIAL_EPOCH_CLS_WEIGHTS/0_75/3_REPLICAS/075_CLS_lr1e-3_headdrop0.3_replica3/output/checkpoint-54520_epoch29_best_model/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at Rostlab/prot_bert_bfd were not used when initializing BertAdapterModel: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertAdapterModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertAdapterModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ibmm_data/TemBERTure/model/BERTSequential/2_LAYERS_HEAD/PARTIAL_EPOCH_CLS_WEIGHTS/1/1E-3/3_REPLICAS/100_CLS_lr1e-3_headdrop0.3_replica1/output/checkpoint-13160_epoch7_best_model/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at Rostlab/prot_bert_bfd were not used when initializing BertAdapterModel: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertAdapterModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertAdapterModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ibmm_data/TemBERTure/model/BERTSequential/2_LAYERS_HEAD/PARTIAL_EPOCH_CLS_WEIGHTS/1/1E-3/3_REPLICAS/100_CLS_lr1e-3_headdrop0.3_replica2/output/checkpoint-11280_epoch6_best_model/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at Rostlab/prot_bert_bfd were not used when initializing BertAdapterModel: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertAdapterModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertAdapterModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ibmm_data/TemBERTure/model/BERTSequential/2_LAYERS_HEAD/PARTIAL_EPOCH_CLS_WEIGHTS/1/1E-3/3_REPLICAS/100_CLS_lr1e-3_headdrop0.3_replica3/output/checkpoint-15040_epoch8_best_model/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at Rostlab/prot_bert_bfd were not used when initializing BertAdapterModel: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertAdapterModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertAdapterModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ibmm_data/TemBERTure/model/BERTSequential/2_LAYERS_HEAD/FULL_CLS_TRAINING/3_REPLICAS/FULL_CLS_lr1e-3_headdrop0.3_replica1/output/checkpoint-13160_epoch7_best_model/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at Rostlab/prot_bert_bfd were not used when initializing BertAdapterModel: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertAdapterModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertAdapterModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ibmm_data/TemBERTure/model/BERTSequential/2_LAYERS_HEAD/FULL_CLS_TRAINING/3_REPLICAS/FULL_CLS_lr1e-3_headdrop0.3_replica2/output/checkpoint-45120_epoch24_best_model/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at Rostlab/prot_bert_bfd were not used when initializing BertAdapterModel: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertAdapterModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertAdapterModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ibmm_data/TemBERTure/model/BERTSequential/2_LAYERS_HEAD/FULL_CLS_TRAINING/3_REPLICAS/FULL_CLS_lr1e-3_headdrop0.3_replica3/output/checkpoint-50760_epoch27_best_model/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at Rostlab/prot_bert_bfd were not used when initializing BertAdapterModel: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertAdapterModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertAdapterModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ibmm_data/TemBERTure/model/BERT_regr/2_LAYER_HEAD/3_REPLICAS/RANDOM_IND_lr1e-3_headdrop0.3_replica1/output/checkpoint-13160_epoch7_best_model/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at Rostlab/prot_bert_bfd were not used when initializing BertAdapterModel: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertAdapterModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertAdapterModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ibmm_data/TemBERTure/model/BERT_regr/2_LAYER_HEAD/3_REPLICAS/RANDOM_IND_lr1e-3_headdrop0.3_replica2/output/checkpoint-3760_epoch2_best_model/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at Rostlab/prot_bert_bfd were not used when initializing BertAdapterModel: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertAdapterModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertAdapterModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ibmm_data/TemBERTure/model/BERT_regr/2_LAYER_HEAD/3_REPLICAS/RANDOM_IND_lr1e-3_headdrop0.3_replica3/output/checkpoint-26320_epoch14_best_model/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at Rostlab/prot_bert_bfd were not used when initializing BertAdapterModel: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertAdapterModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertAdapterModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model0': <temBERTure.temBERTure.TemBERTure object at 0x7ff871d31d30>, 'model1': <temBERTure.temBERTure.TemBERTure object at 0x7ff85c2d5790>, 'model2': <temBERTure.temBERTure.TemBERTure object at 0x7ff85eae5f40>, 'model3': <temBERTure.temBERTure.TemBERTure object at 0x7ff85e4459d0>, 'model4': <temBERTure.temBERTure.TemBERTure object at 0x7ffb38104400>, 'model5': <temBERTure.temBERTure.TemBERTure object at 0x7ff85dfb9f10>, 'model6': <temBERTure.temBERTure.TemBERTure object at 0x7ff85e396fd0>, 'model7': <temBERTure.temBERTure.TemBERTure object at 0x7ff85dc55f70>, 'model8': <temBERTure.temBERTure.TemBERTure object at 0x7ff85d5da3d0>, 'model9': <temBERTure.temBERTure.TemBERTure object at 0x7ff85d20cd60>, 'model10': <temBERTure.temBERTure.TemBERTure object at 0x7ff85d19de80>, 'model11': <temBERTure.temBERTure.TemBERTure object at 0x7ff85ca04e80>, 'model12': <temBERTure.temBERTure.TemBERTure object at 0x7ff85c676f70>, 'model13': <temBERTure.temBERTure.TemBERTure object at 0x7ff85c71d3a0>, 'model14': <temBERTure.temBERTure.TemBERTure object at 0x7ff7c80d1520>, 'model15': <temBERTure.temBERTure.TemBERTure object at 0x7ff7a4116490>, 'model16': <temBERTure.temBERTure.TemBERTure object at 0x7ff7a4052f40>, 'model17': <temBERTure.temBERTure.TemBERTure object at 0x7ff7a4052fd0>}\n"
     ]
    }
   ],
   "source": [
    "from temBERTure.temBERTure import TemBERTure\n",
    "\n",
    "n=0\n",
    "models = {}\n",
    "for p in range(len(categories_path)):\n",
    "    for i in range(1, 4): #n replicas\n",
    "        path=f\"{main_path}{categories_path[p]}/3_REPLICAS/*replica{i}/output/checkpoint*_best_model/\"\n",
    "        path = glob.glob(path)[0]\n",
    "        print(path)\n",
    "        #path='/ibmm_data/TemBERTure/model/BERT_regr/2_LAYER_HEAD/3_REPLICAS/RANDOM_IND_lr1e-3_headdrop0.3_replica3/output/checkpoint-26320_epoch14_best_model/'\n",
    "        model = TemBERTure(adapter_path=path, device='cuda:6')\n",
    "        models[f'model{n}'] = model\n",
    "        n += 1\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sequence</th>\n",
       "      <th>cls_label</th>\n",
       "      <th>tm</th>\n",
       "      <th>id2</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Geobacillus_stearothermophilus229</td>\n",
       "      <td>MEKVYGLIGFPVEHSLSPLMHNDAFARLGIPARYHLFSVEPGQVGA...</td>\n",
       "      <td>1</td>\n",
       "      <td>70.920000</td>\n",
       "      <td>A0A0K2H5Z1_aroE</td>\n",
       "      <td>Geobacillus_stearothermophilus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Geobacillus_stearothermophilus230</td>\n",
       "      <td>MWKKFLSKLGIGAAKVDLVLHRPHVRLGETLEGEFLLEGGSVAQHI...</td>\n",
       "      <td>1</td>\n",
       "      <td>71.730000</td>\n",
       "      <td>A0A0K2H966_GT50_10540</td>\n",
       "      <td>Geobacillus_stearothermophilus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Geobacillus_stearothermophilus233</td>\n",
       "      <td>MKILLAEDDLHLGELIVHLLKKKGIDHIDWVQEGEDAYDYAMAEFY...</td>\n",
       "      <td>1</td>\n",
       "      <td>71.946000</td>\n",
       "      <td>A0A0K2H9T2_GT50_11410</td>\n",
       "      <td>Geobacillus_stearothermophilus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Geobacillus_stearothermophilus239</td>\n",
       "      <td>MRKIVIVGGVAGGATAAARLRRLSEADHIVLFERGEYISFANCGLP...</td>\n",
       "      <td>1</td>\n",
       "      <td>72.421000</td>\n",
       "      <td>A0A0K2HC89_GT50_16915</td>\n",
       "      <td>Geobacillus_stearothermophilus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Geobacillus_stearothermophilus243</td>\n",
       "      <td>MTVGKVYLVGAGPGDEKLITVYGRECLERADVIIYDRLINRKLLRY...</td>\n",
       "      <td>1</td>\n",
       "      <td>74.424000</td>\n",
       "      <td>A0A0K2HCU8_GT50_18150</td>\n",
       "      <td>Geobacillus_stearothermophilus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>Mus_musculus10004</td>\n",
       "      <td>MARDAELARSSGWPWRWLPALLLLQLLRWRCALCALPFTSSRHPGF...</td>\n",
       "      <td>0</td>\n",
       "      <td>52.780000</td>\n",
       "      <td>Q8BGT0_Ostm1</td>\n",
       "      <td>Mus_musculus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>Mus_musculus10005</td>\n",
       "      <td>MTSLSVHTDSPSTQGEMAFNLTILSLTELLSLGGLLGNGVALWLLN...</td>\n",
       "      <td>0</td>\n",
       "      <td>52.780000</td>\n",
       "      <td>Q4V9R2_Mrgpre</td>\n",
       "      <td>Mus_musculus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>Mus_musculus10044</td>\n",
       "      <td>MAGAPGGGELGPAAGEPLLQRPDSGQGSPEPPAHGKPQQGFLSSLF...</td>\n",
       "      <td>0</td>\n",
       "      <td>52.818000</td>\n",
       "      <td>G3UW46_Xrcc6bp1</td>\n",
       "      <td>Mus_musculus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>Mus_musculus13075</td>\n",
       "      <td>MDRSSKRRQVKPLAASLLEALDYDSSDDSDFKVGDASDSEGSGNGS...</td>\n",
       "      <td>0</td>\n",
       "      <td>58.234000</td>\n",
       "      <td>G5E8S0_Phf14</td>\n",
       "      <td>Mus_musculus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>Homo_sapiens111112</td>\n",
       "      <td>MGLSDGEWQQVLNVWGKVEADIAGHGQEVLIRLFTGHPETLEKFDK...</td>\n",
       "      <td>0</td>\n",
       "      <td>67.141257</td>\n",
       "      <td>P68082</td>\n",
       "      <td>Homo_sapiens</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>531 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    id  \\\n",
       "0    Geobacillus_stearothermophilus229   \n",
       "1    Geobacillus_stearothermophilus230   \n",
       "2    Geobacillus_stearothermophilus233   \n",
       "3    Geobacillus_stearothermophilus239   \n",
       "4    Geobacillus_stearothermophilus243   \n",
       "..                                 ...   \n",
       "526                  Mus_musculus10004   \n",
       "527                  Mus_musculus10005   \n",
       "528                  Mus_musculus10044   \n",
       "529                  Mus_musculus13075   \n",
       "530                 Homo_sapiens111112   \n",
       "\n",
       "                                              sequence  cls_label         tm  \\\n",
       "0    MEKVYGLIGFPVEHSLSPLMHNDAFARLGIPARYHLFSVEPGQVGA...          1  70.920000   \n",
       "1    MWKKFLSKLGIGAAKVDLVLHRPHVRLGETLEGEFLLEGGSVAQHI...          1  71.730000   \n",
       "2    MKILLAEDDLHLGELIVHLLKKKGIDHIDWVQEGEDAYDYAMAEFY...          1  71.946000   \n",
       "3    MRKIVIVGGVAGGATAAARLRRLSEADHIVLFERGEYISFANCGLP...          1  72.421000   \n",
       "4    MTVGKVYLVGAGPGDEKLITVYGRECLERADVIIYDRLINRKLLRY...          1  74.424000   \n",
       "..                                                 ...        ...        ...   \n",
       "526  MARDAELARSSGWPWRWLPALLLLQLLRWRCALCALPFTSSRHPGF...          0  52.780000   \n",
       "527  MTSLSVHTDSPSTQGEMAFNLTILSLTELLSLGGLLGNGVALWLLN...          0  52.780000   \n",
       "528  MAGAPGGGELGPAAGEPLLQRPDSGQGSPEPPAHGKPQQGFLSSLF...          0  52.818000   \n",
       "529  MDRSSKRRQVKPLAASLLEALDYDSSDDSDFKVGDASDSEGSGNGS...          0  58.234000   \n",
       "530  MGLSDGEWQQVLNVWGKVEADIAGHGQEVLIRLFTGHPETLEKFDK...          0  67.141257   \n",
       "\n",
       "                       id2                         species  \n",
       "0          A0A0K2H5Z1_aroE  Geobacillus_stearothermophilus  \n",
       "1    A0A0K2H966_GT50_10540  Geobacillus_stearothermophilus  \n",
       "2    A0A0K2H9T2_GT50_11410  Geobacillus_stearothermophilus  \n",
       "3    A0A0K2HC89_GT50_16915  Geobacillus_stearothermophilus  \n",
       "4    A0A0K2HCU8_GT50_18150  Geobacillus_stearothermophilus  \n",
       "..                     ...                             ...  \n",
       "526           Q8BGT0_Ostm1                    Mus_musculus  \n",
       "527          Q4V9R2_Mrgpre                    Mus_musculus  \n",
       "528        G3UW46_Xrcc6bp1                    Mus_musculus  \n",
       "529           G5E8S0_Phf14                    Mus_musculus  \n",
       "530                 P68082                    Homo_sapiens  \n",
       "\n",
       "[531 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test set\n",
    "import pandas as pd\n",
    "test_set = pd.read_csv(\"/ibmm_data/TemBERTure/MultiTaskDataset/FinalDataset/RegressionData/regression_test\",header=None)\n",
    "test_set.columns = ['id','sequence','cls_label','tm','id2','species']\n",
    "test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodelc/anaconda3/envs/temBERTure_datavis/lib/python3.8/site-packages/torch/cuda/__init__.py:155: UserWarning: \n",
      "NVIDIA H100 PCIe with CUDA capability sm_90 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_61 sm_70 sm_75 sm_80 sm_86 compute_37.\n",
      "If you want to use the NVIDIA H100 PCIe GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[73.75225067138672, 51.43948745727539, 51.800086975097656]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = models['model1']\n",
    "predictions = model.predict(test_set['sequence'][:3])\n",
    "print(predictions[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of 18 models \n",
    "models = models\n",
    "\n",
    "# Validation set \n",
    "X_val, y_val = test_set['sequence'],test_set['tm']\n",
    "#X_val, y_val = test_set['sequence'],test_set['cls_label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Ensemble:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model0': <temBERTure.temBERTure.TemBERTure at 0x7f6000651460>,\n",
       " 'model1': <temBERTure.temBERTure.TemBERTure at 0x7f5d4605b790>,\n",
       " 'model2': <temBERTure.temBERTure.TemBERTure at 0x7f5d4c80dac0>,\n",
       " 'model3': <temBERTure.temBERTure.TemBERTure at 0x7f5d4c80dca0>,\n",
       " 'model4': <temBERTure.temBERTure.TemBERTure at 0x7f5d560e5f40>,\n",
       " 'model5': <temBERTure.temBERTure.TemBERTure at 0x7f5d55d08f10>,\n",
       " 'model6': <temBERTure.temBERTure.TemBERTure at 0x7f5d55701760>,\n",
       " 'model7': <temBERTure.temBERTure.TemBERTure at 0x7f5d553293d0>,\n",
       " 'model8': <temBERTure.temBERTure.TemBERTure at 0x7f5d5525cf40>,\n",
       " 'model9': <temBERTure.temBERTure.TemBERTure at 0x7f5d560cdc40>,\n",
       " 'model10': <temBERTure.temBERTure.TemBERTure at 0x7f5d560cdfa0>,\n",
       " 'model11': <temBERTure.temBERTure.TemBERTure at 0x7f5d5474dfa0>,\n",
       " 'model12': <temBERTure.temBERTure.TemBERTure at 0x7f5d543dcdf0>,\n",
       " 'model13': <temBERTure.temBERTure.TemBERTure at 0x7f5d53db6910>,\n",
       " 'model14': <temBERTure.temBERTure.TemBERTure at 0x7f5d539e5520>,\n",
       " 'model15': <temBERTure.temBERTure.TemBERTure at 0x7f5d5366a490>,\n",
       " 'model16': <temBERTure.temBERTure.TemBERTure at 0x7f5d535a6f40>,\n",
       " 'model17': <temBERTure.temBERTure.TemBERTure at 0x7f5d535a6fd0>}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## METHOD 1: Stacking - Debug (using TemBERTureSK class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier, StackingRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from itertools import combinations\n",
    "\n",
    "def calculate_mae(selected_models):\n",
    "    selected_models = list(selected_models)\n",
    "    print('selected',selected_models)\n",
    "    model_list = [model for model in selected_models]\n",
    "    print('model_list',model_list)\n",
    "    stack = StackingRegressor(estimators=model_list, final_estimator=None, passthrough=True)\n",
    "    stack.fit(X_val, y_val)\n",
    "    predictions = stack.predict(X_val)\n",
    "    print(predictions)\n",
    "    mae = mean_absolute_error(y_val, predictions)\n",
    "    return mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_models [('model0', TemBERTureSK(adapter_path='/ibmm_data/TemBERTure/model/BERTSequential/2_LAYERS_HEAD/PARTIAL_EPOCH_CLS_WEIGHTS/0_25/3_REPLICAS/025_CLS_lr1e-3_headdrop0.3_replica1/output/checkpoint-73320_epoch39_best_model/',\n",
      "             device='cuda:6')), ('model1', TemBERTureSK(adapter_path='/ibmm_data/TemBERTure/model/BERTSequential/2_LAYERS_HEAD/PARTIAL_EPOCH_CLS_WEIGHTS/0_25/3_REPLICAS/025_CLS_lr1e-3_headdrop0.3_replica2/output/checkpoint-7520_epoch4_best_model/',\n",
      "             device='cuda:6')), ('model2', TemBERTureSK(adapter_path='/ibmm_data/TemBERTure/model/BERTSequential/2_LAYERS_HEAD/PARTIAL_EPOCH_CLS_WEIGHTS/0_25/3_REPLICAS/025_CLS_lr1e-3_headdrop0.3_replica3/output/checkpoint-31960_epoch17_best_model/',\n",
      "             device='cuda:6')), ('model3', TemBERTureSK(adapter_path='/ibmm_data/TemBERTure/model/BERTSequential/2_LAYERS_HEAD/PARTIAL_EPOCH_CLS_WEIGHTS/0_50/3_REPLICAS/050_CLS_lr1e-3_headdrop0.3_replica1/output/checkpoint-60160_epoch32_best_model/',\n",
      "             device='cuda:6')), ('model4', TemBERTureSK(adapter_path='/ibmm_data/TemBERTure/model/BERTSequential/2_LAYERS_HEAD/PARTIAL_EPOCH_CLS_WEIGHTS/0_50/3_REPLICAS/050_CLS_lr1e-3_headdrop0.3_replica2/output/checkpoint-60160_epoch32_best_model/',\n",
      "             device='cuda:6')), ('model5', TemBERTureSK(adapter_path='/ibmm_data/TemBERTure/model/BERTSequential/2_LAYERS_HEAD/PARTIAL_EPOCH_CLS_WEIGHTS/0_50/3_REPLICAS/050_CLS_lr1e-3_headdrop0.3_replica3/output/checkpoint-13160_epoch7_best_model/',\n",
      "             device='cuda:6')), ('model6', TemBERTureSK(adapter_path='/ibmm_data/TemBERTure/model/BERTSequential/2_LAYERS_HEAD/PARTIAL_EPOCH_CLS_WEIGHTS/0_75/3_REPLICAS/075_CLS_lr1e-3_headdrop0.3_replica1/output/checkpoint-3760_epoch2_best_model/',\n",
      "             device='cuda:6')), ('model7', TemBERTureSK(adapter_path='/ibmm_data/TemBERTure/model/BERTSequential/2_LAYERS_HEAD/PARTIAL_EPOCH_CLS_WEIGHTS/0_75/3_REPLICAS/075_CLS_lr1e-3_headdrop0.3_replica2/output/checkpoint-73320_epoch39_best_model/',\n",
      "             device='cuda:6')), ('model8', TemBERTureSK(adapter_path='/ibmm_data/TemBERTure/model/BERTSequential/2_LAYERS_HEAD/PARTIAL_EPOCH_CLS_WEIGHTS/0_75/3_REPLICAS/075_CLS_lr1e-3_headdrop0.3_replica3/output/checkpoint-54520_epoch29_best_model/',\n",
      "             device='cuda:6')), ('model9', TemBERTureSK(adapter_path='/ibmm_data/TemBERTure/model/BERTSequential/2_LAYERS_HEAD/PARTIAL_EPOCH_CLS_WEIGHTS/1/1E-3/3_REPLICAS/100_CLS_lr1e-3_headdrop0.3_replica1/output/checkpoint-13160_epoch7_best_model/',\n",
      "             device='cuda:6')), ('model10', TemBERTureSK(adapter_path='/ibmm_data/TemBERTure/model/BERTSequential/2_LAYERS_HEAD/PARTIAL_EPOCH_CLS_WEIGHTS/1/1E-3/3_REPLICAS/100_CLS_lr1e-3_headdrop0.3_replica2/output/checkpoint-11280_epoch6_best_model/',\n",
      "             device='cuda:6')), ('model11', TemBERTureSK(adapter_path='/ibmm_data/TemBERTure/model/BERTSequential/2_LAYERS_HEAD/PARTIAL_EPOCH_CLS_WEIGHTS/1/1E-3/3_REPLICAS/100_CLS_lr1e-3_headdrop0.3_replica3/output/checkpoint-15040_epoch8_best_model/',\n",
      "             device='cuda:6')), ('model12', TemBERTureSK(adapter_path='/ibmm_data/TemBERTure/model/BERTSequential/2_LAYERS_HEAD/FULL_CLS_TRAINING/3_REPLICAS/FULL_CLS_lr1e-3_headdrop0.3_replica1/output/checkpoint-13160_epoch7_best_model/',\n",
      "             device='cuda:6')), ('model13', TemBERTureSK(adapter_path='/ibmm_data/TemBERTure/model/BERTSequential/2_LAYERS_HEAD/FULL_CLS_TRAINING/3_REPLICAS/FULL_CLS_lr1e-3_headdrop0.3_replica2/output/checkpoint-45120_epoch24_best_model/',\n",
      "             device='cuda:6')), ('model14', TemBERTureSK(adapter_path='/ibmm_data/TemBERTure/model/BERTSequential/2_LAYERS_HEAD/FULL_CLS_TRAINING/3_REPLICAS/FULL_CLS_lr1e-3_headdrop0.3_replica3/output/checkpoint-50760_epoch27_best_model/',\n",
      "             device='cuda:6')), ('model15', TemBERTureSK(adapter_path='/ibmm_data/TemBERTure/model/BERT_regr/2_LAYER_HEAD/3_REPLICAS/RANDOM_IND_lr1e-3_headdrop0.3_replica1/output/checkpoint-13160_epoch7_best_model/',\n",
      "             device='cuda:6')), ('model16', TemBERTureSK(adapter_path='/ibmm_data/TemBERTure/model/BERT_regr/2_LAYER_HEAD/3_REPLICAS/RANDOM_IND_lr1e-3_headdrop0.3_replica2/output/checkpoint-3760_epoch2_best_model/',\n",
      "             device='cuda:6')), ('model17', TemBERTureSK(adapter_path='/ibmm_data/TemBERTure/model/BERT_regr/2_LAYER_HEAD/3_REPLICAS/RANDOM_IND_lr1e-3_headdrop0.3_replica3/output/checkpoint-26320_epoch14_best_model/',\n",
      "             device='cuda:6'))]\n",
      "combinations <itertools.combinations object at 0x7f1e27c3c090>\n",
      "ensemble [('model0', TemBERTureSK(adapter_path='/ibmm_data/TemBERTure/model/BERTSequential/2_LAYERS_HEAD/PARTIAL_EPOCH_CLS_WEIGHTS/0_25/3_REPLICAS/025_CLS_lr1e-3_headdrop0.3_replica1/output/checkpoint-73320_epoch39_best_model/',\n",
      "             device='cuda:6'))]\n",
      "selected [('model0', TemBERTureSK(adapter_path='/ibmm_data/TemBERTure/model/BERTSequential/2_LAYERS_HEAD/PARTIAL_EPOCH_CLS_WEIGHTS/0_25/3_REPLICAS/025_CLS_lr1e-3_headdrop0.3_replica1/output/checkpoint-73320_epoch39_best_model/',\n",
      "             device='cuda:6'))]\n",
      "model_list [('model0', TemBERTureSK(adapter_path='/ibmm_data/TemBERTure/model/BERTSequential/2_LAYERS_HEAD/PARTIAL_EPOCH_CLS_WEIGHTS/0_25/3_REPLICAS/025_CLS_lr1e-3_headdrop0.3_replica1/output/checkpoint-73320_epoch39_best_model/',\n",
      "             device='cuda:6'))]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The estimator TemBERTureSK should be a regressor.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ensemble \u001b[38;5;129;01min\u001b[39;00m combinations_r:\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mensemble\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;28mlist\u001b[39m(ensemble))\n\u001b[0;32m---> 10\u001b[0m     mae \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_mae\u001b[49m\u001b[43m(\u001b[49m\u001b[43mensemble\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36mcalculate_mae\u001b[0;34m(selected_models)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_list\u001b[39m\u001b[38;5;124m'\u001b[39m,model_list)\n\u001b[1;32m     11\u001b[0m stack \u001b[38;5;241m=\u001b[39m StackingRegressor(estimators\u001b[38;5;241m=\u001b[39mmodel_list, final_estimator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, passthrough\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 12\u001b[0m \u001b[43mstack\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m predictions \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39mpredict(X_val)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(predictions)\n",
      "File \u001b[0;32m~/anaconda3/envs/temBERTure_datavis/lib/python3.8/site-packages/sklearn/ensemble/_stacking.py:957\u001b[0m, in \u001b[0;36mStackingRegressor.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    935\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit the estimators.\u001b[39;00m\n\u001b[1;32m    936\u001b[0m \n\u001b[1;32m    937\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    954\u001b[0m \u001b[38;5;124;03m    Returns a fitted instance.\u001b[39;00m\n\u001b[1;32m    955\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    956\u001b[0m y \u001b[38;5;241m=\u001b[39m column_or_1d(y, warn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 957\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/temBERTure_datavis/lib/python3.8/site-packages/sklearn/ensemble/_stacking.py:195\u001b[0m, in \u001b[0;36m_BaseStacking.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m    193\u001b[0m \u001b[38;5;66;03m# all_estimators contains all estimators, the one to be fitted and the\u001b[39;00m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# 'drop' string.\u001b[39;00m\n\u001b[0;32m--> 195\u001b[0m names, all_estimators \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_estimators\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_final_estimator()\n\u001b[1;32m    198\u001b[0m stack_method \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstack_method] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(all_estimators)\n",
      "File \u001b[0;32m~/anaconda3/envs/temBERTure_datavis/lib/python3.8/site-packages/sklearn/ensemble/_base.py:303\u001b[0m, in \u001b[0;36m_BaseHeterogeneousEnsemble._validate_estimators\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m est \u001b[38;5;129;01min\u001b[39;00m estimators:\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m est \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdrop\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_estimator_type(est):\n\u001b[0;32m--> 303\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    304\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe estimator \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m should be a \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    305\u001b[0m                 est\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, is_estimator_type\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m[\u001b[38;5;241m3\u001b[39m:]\n\u001b[1;32m    306\u001b[0m             )\n\u001b[1;32m    307\u001b[0m         )\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m names, estimators\n",
      "\u001b[0;31mValueError\u001b[0m: The estimator TemBERTureSK should be a regressor."
     ]
    }
   ],
   "source": [
    "#all_models = list(self.models.keys())\n",
    "all_models = list(models.items())\n",
    "print('all_models',all_models)\n",
    "\n",
    "for r in range(1, len(all_models) + 1):\n",
    "    combinations_r = combinations(all_models, r)\n",
    "    print('combinations',combinations_r)\n",
    "    for ensemble in combinations_r:\n",
    "        print('ensemble',list(ensemble))\n",
    "        mae = calculate_mae(ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** StackingEnsemble ***\n",
      "all_models [('model0', <temBERTure.temBERTure.TemBERTure object at 0x7f0be64063a0>), ('model1', <temBERTure.temBERTure.TemBERTure object at 0x7f095307c7f0>), ('model2', <temBERTure.temBERTure.TemBERTure object at 0x7f0952f82f70>), ('model3', <temBERTure.temBERTure.TemBERTure object at 0x7f0952f82fa0>), ('model4', <temBERTure.temBERTure.TemBERTure object at 0x7f0c180875b0>), ('model5', <temBERTure.temBERTure.TemBERTure object at 0x7f093c38deb0>), ('model6', <temBERTure.temBERTure.TemBERTure object at 0x7f093c3e38b0>), ('model7', <temBERTure.temBERTure.TemBERTure object at 0x7f095223b190>), ('model8', <temBERTure.temBERTure.TemBERTure object at 0x7f09519dbdf0>), ('model9', <temBERTure.temBERTure.TemBERTure object at 0x7f0951a28fd0>), ('model10', <temBERTure.temBERTure.TemBERTure object at 0x7f0950fcb340>), ('model11', <temBERTure.temBERTure.TemBERTure object at 0x7f0950fcb4f0>), ('model12', <temBERTure.temBERTure.TemBERTure object at 0x7f0950b8df40>), ('model13', <temBERTure.temBERTure.TemBERTure object at 0x7f0950b8df70>), ('model14', <temBERTure.temBERTure.TemBERTure object at 0x7f09501b72b0>), ('model15', <temBERTure.temBERTure.TemBERTure object at 0x7f093fde9e20>), ('model16', <temBERTure.temBERTure.TemBERTure object at 0x7f093fcc7f10>), ('model17', <temBERTure.temBERTure.TemBERTure object at 0x7f093f649520>)]\n",
      "<itertools.combinations object at 0x7f0c180e7810>\n",
      "ensemble (('model0', <temBERTure.temBERTure.TemBERTure object at 0x7f0be64063a0>),)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "('model0', <temBERTure.temBERTure.TemBERTure object at 0x7f0be64063a0>)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01manalysis\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StackingEnsemble\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m*** StackingEnsemble ***\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m selected_models, best_mae \u001b[38;5;241m=\u001b[39m \u001b[43mStackingEnsemble\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[43m,\u001b[49m\u001b[43mX_val\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mensemble\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Output the final selected models and their performance\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinal selected models:\u001b[39m\u001b[38;5;124m\"\u001b[39m, selected_models)\n",
      "File \u001b[0;32m/ibmm_data/TemBERTure/model/code/analysis/ensemble.py:248\u001b[0m, in \u001b[0;36mStackingEnsemble.ensemble\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ensemble \u001b[38;5;129;01min\u001b[39;00m combinations_r:\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mensemble\u001b[39m\u001b[38;5;124m'\u001b[39m,ensemble)\n\u001b[0;32m--> 248\u001b[0m     mae \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalculate_mae\u001b[49m\u001b[43m(\u001b[49m\u001b[43mensemble\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mae \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_mae:\n\u001b[1;32m    250\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_mae \u001b[38;5;241m=\u001b[39m mae\n",
      "File \u001b[0;32m/ibmm_data/TemBERTure/model/code/analysis/ensemble.py:230\u001b[0m, in \u001b[0;36mStackingEnsemble.calculate_mae\u001b[0;34m(self, selected_models)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_mae\u001b[39m(\u001b[38;5;28mself\u001b[39m, selected_models):\n\u001b[0;32m--> 230\u001b[0m     model_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodels[model] \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m selected_models]\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_list\u001b[39m\u001b[38;5;124m'\u001b[39m,model_list)\n\u001b[1;32m    232\u001b[0m     stack \u001b[38;5;241m=\u001b[39m StackingRegressor(estimators\u001b[38;5;241m=\u001b[39mmodel_list, final_estimator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, passthrough\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/ibmm_data/TemBERTure/model/code/analysis/ensemble.py:230\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_mae\u001b[39m(\u001b[38;5;28mself\u001b[39m, selected_models):\n\u001b[0;32m--> 230\u001b[0m     model_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m selected_models]\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_list\u001b[39m\u001b[38;5;124m'\u001b[39m,model_list)\n\u001b[1;32m    232\u001b[0m     stack \u001b[38;5;241m=\u001b[39m StackingRegressor(estimators\u001b[38;5;241m=\u001b[39mmodel_list, final_estimator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, passthrough\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyError\u001b[0m: ('model0', <temBERTure.temBERTure.TemBERTure object at 0x7f0be64063a0>)"
     ]
    }
   ],
   "source": [
    "from analysis.ensemble import StackingEnsemble\n",
    "print('*** StackingEnsemble ***')\n",
    "selected_models, best_mae = StackingEnsemble(models=models,X_val=X_val, y_val=y_val).ensemble()\n",
    "\n",
    "# Output the final selected models and their performance\n",
    "print(\"Final selected models:\", selected_models)\n",
    "print(\"Best MAE:\", best_mae)\n",
    "print('')\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## METHOD 1: Greedy Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model0': <temBERTure.temBERTure.TemBERTure at 0x7f15245585e0>,\n",
       " 'model1': <temBERTure.temBERTure.TemBERTure at 0x7f124c337790>,\n",
       " 'model2': <temBERTure.temBERTure.TemBERTure at 0x7f124ce9aac0>}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys= ['model0','model1','model2']\n",
    "models_tmp = {key: models[key] for key in keys}\n",
    "models_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** GreedyAlgorithmEnsemble  ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 13.17it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13.90it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13.74it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13.82it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13.89it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13.77it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13.77it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13.83it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13.82it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13.13it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13.69it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13.81it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13.85it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13.84it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13.85it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best selected model model8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 13.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model mae model8\n",
      "remaining ['model0', 'model1', 'model10', 'model11', 'model12', 'model13', 'model14', 'model15', 'model16', 'model17', 'model2', 'model3', 'model4', 'model5', 'model6', 'model7', 'model9']\n",
      "remaining 17\n",
      "candidates [('model0',), ('model1',), ('model10',), ('model11',), ('model12',), ('model13',), ('model14',), ('model15',), ('model16',), ('model17',), ('model2',), ('model3',), ('model4',), ('model5',), ('model6',), ('model7',), ('model9',)]\n",
      "current models ['model8', 'model0']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 13.84it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current models ['model8', 'model1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 13.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current models ['model8', 'model10']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 13.90it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current models ['model8', 'model11']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 13.91it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current models ['model8', 'model12']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 13.86it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current models ['model8', 'model13']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 13.53it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current models ['model8', 'model14']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 13.85it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current models ['model8', 'model15']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 13.84it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current models ['model8', 'model16']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 13.89it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current models ['model8', 'model17']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 13.91it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current models ['model8', 'model2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 13.91it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current models ['model8', 'model3']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 13.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current models ['model8', 'model4']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 13.90it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current models ['model8', 'model5']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 13.90it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current models ['model8', 'model6']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 13.90it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current models ['model8', 'model7']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 13.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current models ['model8', 'model9']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 13.85it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remaining ['model0', 'model1', 'model10', 'model11', 'model12', 'model13', 'model14', 'model15', 'model16', 'model17', 'model2', 'model3', 'model4', 'model5', 'model6', 'model7', 'model9']\n",
      "remaining 17\n",
      "candidates [('model0',), ('model1',), ('model10',), ('model11',), ('model12',), ('model13',), ('model14',), ('model15',), ('model16',), ('model17',), ('model2',), ('model3',), ('model4',), ('model5',), ('model6',), ('model7',), ('model9',)]\n",
      "current models ['model8', 'model0']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 13.89it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current models ['model8', 'model1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 13.90it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current models ['model8', 'model10']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 13.90it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current models ['model8', 'model11']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 13.90it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current models ['model8', 'model12']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 13.91it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current models ['model8', 'model13']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 13.90it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current models ['model8', 'model14']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 13.92it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current models ['model8', 'model15']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 13.91it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current models ['model8', 'model16']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 13.89it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current models ['model8', 'model17']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 13.91it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current models ['model8', 'model2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 13.91it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current models ['model8', 'model3']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 13.91it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current models ['model8', 'model4']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 13.73it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current models ['model8', 'model5']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 13.86it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current models ['model8', 'model6']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 13.91it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current models ['model8', 'model7']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 13.89it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current models ['model8', 'model9']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 13.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remaining ['model0', 'model1', 'model10', 'model11', 'model12', 'model13', 'model14', 'model15', 'model16', 'model17', 'model2', 'model3', 'model4', 'model5', 'model6', 'model7', 'model9']\n",
      "remaining 17\n",
      "candidates [('model0',), ('model1',), ('model10',), ('model11',), ('model12',), ('model13',), ('model14',), ('model15',), ('model16',), ('model17',), ('model2',), ('model3',), ('model4',), ('model5',), ('model6',), ('model7',), ('model9',)]\n",
      "current models ['model8', 'model0']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 13.89it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current models ['model8', 'model1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 13.91it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current models ['model8', 'model10']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 13.89it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current models ['model8', 'model11']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 13.91it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current models ['model8', 'model12']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 13.89it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current models ['model8', 'model13']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 13.91it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current models ['model8', 'model14']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 13.90it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current models ['model8', 'model15']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 13.90it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current models ['model8', 'model16']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 13.90it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current models ['model8', 'model17']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 13.90it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current models ['model8', 'model2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 13.90it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current models ['model8', 'model3']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 13.90it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current models ['model8', 'model4']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 13.91it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current models ['model8', 'model5']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 13.90it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current models ['model8', 'model6']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 13.91it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current models ['model8', 'model7']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 13.90it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current models ['model8', 'model9']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 13.89it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final selected models: ['model8']\n",
      "Best MAE: 7.107450897216798\n",
      "Final selected models: ['model8']\n",
      "Best MAE: 7.107450897216798\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from analysis.ensemble import GreedyAlgorithmEnsemble\n",
    "print('*** GreedyAlgorithmEnsemble  ***')\n",
    "selected_models, best_mae = GreedyAlgorithmEnsemble(models=OrderedDict(models),X_val=X_val[:3], y_val=y_val[:3]).ensemble()\n",
    "\n",
    "# Output the final selected models and their performance\n",
    "print(\"Final selected models:\", selected_models)\n",
    "print(\"Best MAE:\", best_mae)\n",
    "print('')\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## METHOD 2: Weighted Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** WeightedAverageEnsemble ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:16<00:00,  2.02it/s]\n",
      "100%|██████████| 34/34 [00:16<00:00,  2.02it/s]\n",
      "100%|██████████| 34/34 [00:16<00:00,  2.02it/s]\n",
      "100%|██████████| 34/34 [00:16<00:00,  2.01it/s]\n",
      "100%|██████████| 34/34 [00:16<00:00,  2.00it/s]\n",
      "100%|██████████| 34/34 [00:16<00:00,  2.00it/s]\n",
      "100%|██████████| 34/34 [00:16<00:00,  2.00it/s]\n",
      "100%|██████████| 34/34 [00:16<00:00,  2.00it/s]\n",
      "100%|██████████| 34/34 [00:16<00:00,  2.00it/s]\n",
      "100%|██████████| 34/34 [00:16<00:00,  2.00it/s]\n",
      "100%|██████████| 34/34 [00:17<00:00,  2.00it/s]\n",
      "100%|██████████| 34/34 [00:16<00:00,  2.00it/s]\n",
      "100%|██████████| 34/34 [00:16<00:00,  2.00it/s]\n",
      "100%|██████████| 34/34 [00:17<00:00,  2.00it/s]\n",
      "100%|██████████| 34/34 [00:17<00:00,  2.00it/s]\n",
      "100%|██████████| 34/34 [00:16<00:00,  2.00it/s]\n",
      "100%|██████████| 34/34 [00:16<00:00,  2.00it/s]\n",
      "100%|██████████| 34/34 [00:16<00:00,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best selected model model5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:16<00:00,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model mae model5\n",
      "remaining ['model0', 'model1', 'model10', 'model11', 'model12', 'model13', 'model14', 'model15', 'model16', 'model17', 'model2', 'model3', 'model4', 'model6', 'model7', 'model8', 'model9']\n",
      "remaining 17\n",
      "candidates [('model0',), ('model1',), ('model10',), ('model11',), ('model12',), ('model13',), ('model14',), ('model15',), ('model16',), ('model17',), ('model2',), ('model3',), ('model4',), ('model6',), ('model7',), ('model8',), ('model9',)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:16<00:00,  2.00it/s]\n",
      "100%|██████████| 34/34 [00:16<00:00,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current mae 6.341894053365407\n",
      "Selected models: ['model5', 'model0']\n",
      "Current MAE: 6.341894053365407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:16<00:00,  2.00it/s]\n",
      "100%|██████████| 34/34 [00:16<00:00,  2.00it/s]\n",
      "100%|██████████| 34/34 [00:16<00:00,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current mae 6.3790813042297785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:16<00:00,  2.00it/s]\n",
      "100%|██████████| 34/34 [00:16<00:00,  2.00it/s]\n",
      "100%|██████████| 34/34 [00:16<00:00,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current mae 6.337461611237739\n",
      "Selected models: ['model5', 'model0', 'model10']\n",
      "Current MAE: 6.337461611237739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:16<00:00,  2.00it/s]\n",
      "100%|██████████| 34/34 [00:16<00:00,  2.00it/s]\n",
      "100%|██████████| 34/34 [00:16<00:00,  2.00it/s]\n",
      "100%|██████████| 34/34 [00:16<00:00,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current mae 6.433587997969798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:16<00:00,  2.00it/s]\n",
      "100%|██████████| 34/34 [00:16<00:00,  2.00it/s]\n",
      "100%|██████████| 34/34 [00:16<00:00,  2.00it/s]\n",
      "100%|██████████| 34/34 [00:16<00:00,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current mae 6.312297050338651\n",
      "Selected models: ['model5', 'model0', 'model10', 'model12']\n",
      "Current MAE: 6.312297050338651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:16<00:00,  2.00it/s]\n",
      "100%|██████████| 34/34 [00:16<00:00,  2.01it/s]\n",
      "100%|██████████| 34/34 [00:16<00:00,  2.00it/s]\n",
      "100%|██████████| 34/34 [00:16<00:00,  2.00it/s]\n",
      "100%|██████████| 34/34 [00:16<00:00,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current mae 6.323850632134626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:16<00:00,  2.00it/s]\n",
      "100%|██████████| 34/34 [00:16<00:00,  2.00it/s]\n",
      "100%|██████████| 34/34 [00:16<00:00,  2.00it/s]\n",
      "100%|██████████| 34/34 [00:16<00:00,  2.00it/s]\n",
      "100%|██████████| 34/34 [00:17<00:00,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current mae 6.352463630170337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:16<00:00,  2.00it/s]\n",
      "100%|██████████| 34/34 [00:16<00:00,  2.00it/s]\n",
      "100%|██████████| 34/34 [00:16<00:00,  2.00it/s]\n",
      "100%|██████████| 34/34 [00:16<00:00,  2.00it/s]\n",
      "100%|██████████| 34/34 [00:16<00:00,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current mae 6.2631723241601565\n",
      "Selected models: ['model5', 'model0', 'model10', 'model12', 'model15']\n",
      "Current MAE: 6.2631723241601565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:16<00:00,  2.00it/s]\n",
      "100%|██████████| 34/34 [00:16<00:00,  2.00it/s]\n",
      "100%|██████████| 34/34 [00:16<00:00,  2.00it/s]\n",
      "100%|██████████| 34/34 [00:16<00:00,  2.00it/s]\n",
      "100%|██████████| 34/34 [00:16<00:00,  2.00it/s]\n",
      "100%|██████████| 34/34 [00:16<00:00,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current mae 6.230525307130671\n",
      "Selected models: ['model5', 'model0', 'model10', 'model12', 'model15', 'model16']\n",
      "Current MAE: 6.230525307130671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:16<00:00,  2.00it/s]\n",
      "100%|██████████| 34/34 [00:16<00:00,  2.00it/s]\n",
      "100%|██████████| 34/34 [00:16<00:00,  2.00it/s]\n",
      " 79%|███████▉  | 27/34 [00:13<00:03,  1.96it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01manalysis\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m WeightedAverageEnsemble\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m*** WeightedAverageEnsemble ***\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m selected_models, best_mae \u001b[38;5;241m=\u001b[39m \u001b[43mWeightedAverageEnsemble\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[43m,\u001b[49m\u001b[43mX_val\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbudget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m9\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mensemble\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Output the final selected models and their performance\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinal selected models:\u001b[39m\u001b[38;5;124m\"\u001b[39m, selected_models)\n",
      "File \u001b[0;32m/ibmm_data/TemBERTure/model/code/analysis/ensemble.py:62\u001b[0m, in \u001b[0;36mWeightedAverageEnsemble.ensemble\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     60\u001b[0m candidate_models_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(candidate_model)\n\u001b[1;32m     61\u001b[0m current_models \u001b[38;5;241m=\u001b[39m selected_models \u001b[38;5;241m+\u001b[39m candidate_models_list\n\u001b[0;32m---> 62\u001b[0m current_mae \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalculate_mae\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_models\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcurrent mae\u001b[39m\u001b[38;5;124m'\u001b[39m, current_mae)\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m current_mae \u001b[38;5;241m<\u001b[39m best_mae:\n",
      "File \u001b[0;32m/ibmm_data/TemBERTure/model/code/analysis/ensemble.py:36\u001b[0m, in \u001b[0;36mWeightedAverageEnsemble.calculate_mae\u001b[0;34m(self, selected_models)\u001b[0m\n\u001b[1;32m     33\u001b[0m predictions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros_like(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_val)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m selected_models:\n\u001b[0;32m---> 36\u001b[0m     predictions \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX_val\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m ensemble_prediction \u001b[38;5;241m=\u001b[39m predictions \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(selected_models)\n\u001b[1;32m     39\u001b[0m mae \u001b[38;5;241m=\u001b[39m mean_absolute_error(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_val, ensemble_prediction)\n",
      "File \u001b[0;32m/ibmm_data/TemBERTure/model/code/temBERTure/temBERTure.py:49\u001b[0m, in \u001b[0;36mTemBERTure.predict\u001b[0;34m(self, input_texts)\u001b[0m\n\u001b[1;32m     47\u001b[0m     batch_input \u001b[38;5;241m=\u001b[39m input_texts[i \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size: (i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size]\n\u001b[1;32m     48\u001b[0m     encoded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer(batch_input, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m---> 49\u001b[0m     y_preds \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mencoded\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mlogits\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassification\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     52\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39marray(y_preds)))\n",
      "File \u001b[0;32m~/anaconda3/envs/temBERTure_datavis/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/temBERTure_datavis/lib/python3.8/site-packages/transformers/adapters/models/bert/adapter_model.py:63\u001b[0m, in \u001b[0;36mBertAdapterModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict, head, output_adapter_gating_scores, output_adapter_fusion_attentions, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m inputs_embeds \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     56\u001b[0m     inputs_embeds\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, inputs_embeds\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m), inputs_embeds\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     59\u001b[0m )\n\u001b[1;32m     61\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m---> 63\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_adapter_gating_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_adapter_gating_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_adapter_fusion_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_adapter_fusion_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m    \u001b[49m\u001b[43madapter_input_parallelized\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43madapter_input_parallelized\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m# BERT & RoBERTa return the pooled output as second item, we don't need that in these heads\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict:\n",
      "File \u001b[0;32m~/anaconda3/envs/temBERTure_datavis/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/temBERTure_datavis/lib/python3.8/site-packages/transformers/adapters/context.py:108\u001b[0m, in \u001b[0;36mForwardContext.wrap.<locals>.wrapper_func\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m ctx:\n\u001b[1;32m    105\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    106\u001b[0m         k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mcontext_attributes\n\u001b[1;32m    107\u001b[0m     }\n\u001b[0;32m--> 108\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;66;03m# append output attributes\u001b[39;00m\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results, \u001b[38;5;28mtuple\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/envs/temBERTure_datavis/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:1053\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1044\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[1;32m   1045\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1046\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1049\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[1;32m   1050\u001b[0m )\n\u001b[1;32m   1051\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minvertible_adapters_forward(embedding_output)\n\u001b[0;32m-> 1053\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1054\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1055\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1056\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1057\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1058\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1059\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1060\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1061\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1062\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1063\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1064\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1065\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1066\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/temBERTure_datavis/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/temBERTure_datavis/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:634\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    625\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[1;32m    626\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m    627\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    631\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    632\u001b[0m     )\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 634\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    636\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    638\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    639\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    640\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    641\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    642\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    644\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    645\u001b[0m (attention_mask,) \u001b[38;5;241m=\u001b[39m adjust_tensors_for_parallel(hidden_states, attention_mask)\n",
      "File \u001b[0;32m~/anaconda3/envs/temBERTure_datavis/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/temBERTure_datavis/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:562\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    559\u001b[0m     cross_attn_present_key_value \u001b[38;5;241m=\u001b[39m cross_attention_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    560\u001b[0m     present_key_value \u001b[38;5;241m=\u001b[39m present_key_value \u001b[38;5;241m+\u001b[39m cross_attn_present_key_value\n\u001b[0;32m--> 562\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed_forward_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    565\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m outputs\n\u001b[1;32m    567\u001b[0m \u001b[38;5;66;03m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/temBERTure_datavis/lib/python3.8/site-packages/transformers/pytorch_utils.py:249\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(output_chunks, dim\u001b[38;5;241m=\u001b[39mchunk_dim)\n\u001b[0;32m--> 249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/temBERTure_datavis/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:575\u001b[0m, in \u001b[0;36mBertLayer.feed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[1;32m    574\u001b[0m     intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate(attention_output)\n\u001b[0;32m--> 575\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mintermediate_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    576\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "File \u001b[0;32m~/anaconda3/envs/temBERTure_datavis/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/temBERTure_datavis/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:489\u001b[0m, in \u001b[0;36mBertOutput.forward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    487\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdense(hidden_states)\n\u001b[1;32m    488\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(hidden_states)\n\u001b[0;32m--> 489\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madapter_layer_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLayerNorm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[0;32m~/anaconda3/envs/temBERTure_datavis/lib/python3.8/site-packages/transformers/adapters/layer.py:537\u001b[0m, in \u001b[0;36mAdapterLayer.adapter_layer_forward\u001b[0;34m(self, hidden_states, residual_input, layer_norm)\u001b[0m\n\u001b[1;32m    534\u001b[0m input_hidden_states \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(adapter_setup, Stack):\n\u001b[0;32m--> 537\u001b[0m     hidden_states, _, residual_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madapter_stack\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    538\u001b[0m \u001b[43m        \u001b[49m\u001b[43madapter_setup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresidual_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_norm\u001b[49m\n\u001b[1;32m    539\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    540\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(adapter_setup, Fuse):\n\u001b[1;32m    541\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madapter_fusion(adapter_setup, hidden_states, residual_input, layer_norm)\n",
      "File \u001b[0;32m~/anaconda3/envs/temBERTure_datavis/lib/python3.8/site-packages/transformers/adapters/layer.py:230\u001b[0m, in \u001b[0;36mAdapterLayer.adapter_stack\u001b[0;34m(self, adapter_setup, hidden_states, input_tensor, layer_norm, lvl)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m adapter_stack_layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madapters:\n\u001b[1;32m    229\u001b[0m     adapter_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madapters[adapter_stack_layer]\n\u001b[0;32m--> 230\u001b[0m     hidden_states, _, residual \u001b[38;5;241m=\u001b[39m \u001b[43madapter_layer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpre_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_norm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m     context \u001b[38;5;241m=\u001b[39m ForwardContext\u001b[38;5;241m.\u001b[39mget_context()\n\u001b[1;32m    232\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m adapter_layer(\n\u001b[1;32m    233\u001b[0m         hidden_states, residual_input\u001b[38;5;241m=\u001b[39mresidual, output_gating\u001b[38;5;241m=\u001b[39mcontext\u001b[38;5;241m.\u001b[39moutput_adapter_gating_scores\n\u001b[1;32m    234\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/temBERTure_datavis/lib/python3.8/site-packages/transformers/adapters/modeling.py:157\u001b[0m, in \u001b[0;36mAdapter.pre_forward\u001b[0;34m(self, hidden_states, input_tensor, layer_norm, fusion_config)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moriginal_ln_before:\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m layer_norm:\n\u001b[0;32m--> 157\u001b[0m         hidden_states \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    159\u001b[0m         hidden_states \u001b[38;5;241m=\u001b[39m hidden_states \u001b[38;5;241m+\u001b[39m input_tensor\n",
      "File \u001b[0;32m~/anaconda3/envs/temBERTure_datavis/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/temBERTure_datavis/lib/python3.8/site-packages/torch/nn/modules/normalization.py:190\u001b[0m, in \u001b[0;36mLayerNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalized_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/temBERTure_datavis/lib/python3.8/site-packages/torch/nn/functional.py:2515\u001b[0m, in \u001b[0;36mlayer_norm\u001b[0;34m(input, normalized_shape, weight, bias, eps)\u001b[0m\n\u001b[1;32m   2511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_variadic(\u001b[38;5;28minput\u001b[39m, weight, bias):\n\u001b[1;32m   2512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m   2513\u001b[0m         layer_norm, (\u001b[38;5;28minput\u001b[39m, weight, bias), \u001b[38;5;28minput\u001b[39m, normalized_shape, weight\u001b[38;5;241m=\u001b[39mweight, bias\u001b[38;5;241m=\u001b[39mbias, eps\u001b[38;5;241m=\u001b[39meps\n\u001b[1;32m   2514\u001b[0m     )\n\u001b[0;32m-> 2515\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalized_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from analysis.ensemble import WeightedAverageEnsemble\n",
    "print('*** WeightedAverageEnsemble ***')\n",
    "selected_models, best_mae = WeightedAverageEnsemble(models=models,X_val=X_val, y_val=y_val,budget=9).ensemble()\n",
    "\n",
    "# Output the final selected models and their performance\n",
    "print(\"Final selected models:\", selected_models)\n",
    "print(\"Best MAE:\", best_mae)\n",
    "print('')\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## METHOD 3: Classification Based Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at Rostlab/prot_bert_bfd were not used when initializing BertAdapterModel: ['cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertAdapterModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertAdapterModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from temBERTure.temBERTure import TemBERTure\n",
    "classifier = TemBERTure(adapter_path='/ibmm_data/TemBERTure/model/BERT_cls/BEST_MODEL/lr_1e-5_headropout01/output/best_model_epoch4/', device='cuda:7', task ='classification')\n",
    "#classifier.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** ClassificationBasedEnsemble ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Greedy optimization for non-thermophilic ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 18.46it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 18.98it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 18.71it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 18.42it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 18.67it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 18.73it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 18.66it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 18.60it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 18.71it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 18.69it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 18.60it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 18.80it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 18.77it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 18.70it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 18.68it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 18.60it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 18.65it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 18.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best selected model model8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 18.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model mae model8\n",
      "remaining ['model0', 'model1', 'model10', 'model11', 'model12', 'model13', 'model14', 'model15', 'model16', 'model17', 'model2', 'model3', 'model4', 'model5', 'model6', 'model7', 'model9']\n",
      "remaining 17\n",
      "remaining models ['model0', 'model1', 'model10', 'model11', 'model12', 'model13', 'model14', 'model15', 'model16', 'model17', 'model2', 'model3', 'model4', 'model5', 'model6', 'model7', 'model9']\n",
      "remaining 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 19.04it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.07it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.08it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.04it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.07it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.04it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.07it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.07it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.03it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.04it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.02it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 18.95it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.07it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.08it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.07it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 18.93it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.02it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.07it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 18.95it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.03it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remaining ['model0', 'model1', 'model10', 'model11', 'model12', 'model13', 'model14', 'model15', 'model16', 'model17', 'model2', 'model3', 'model4', 'model5', 'model6', 'model7', 'model9']\n",
      "remaining 17\n",
      "remaining models ['model0', 'model1', 'model10', 'model11', 'model12', 'model13', 'model14', 'model15', 'model16', 'model17', 'model2', 'model3', 'model4', 'model5', 'model6', 'model7', 'model9']\n",
      "remaining 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 19.00it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.07it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 18.94it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.07it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.07it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 18.97it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.03it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.04it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.09it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.11it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.07it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.04it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 18.76it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.07it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.07it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.07it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 18.97it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.02it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.02it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.07it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.01it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remaining ['model0', 'model1', 'model10', 'model11', 'model12', 'model13', 'model14', 'model15', 'model16', 'model17', 'model2', 'model3', 'model4', 'model5', 'model6', 'model7', 'model9']\n",
      "remaining 17\n",
      "remaining models ['model0', 'model1', 'model10', 'model11', 'model12', 'model13', 'model14', 'model15', 'model16', 'model17', 'model2', 'model3', 'model4', 'model5', 'model6', 'model7', 'model9']\n",
      "remaining 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 19.03it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.03it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.01it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 18.93it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.09it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.07it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.07it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.04it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.02it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.04it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.07it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.03it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.08it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.07it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.08it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.09it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.04it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 18.97it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.07it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final selected models: ['model8']\n",
      "Best MAE: 6.785047042846678\n",
      "*** Greedy optimization for thermophilic ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  3.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.86it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.86it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.89it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.90it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.89it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.89it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.89it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.90it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best selected model model11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  3.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model mae model11\n",
      "remaining ['model0', 'model1', 'model10', 'model12', 'model13', 'model14', 'model15', 'model16', 'model17', 'model2', 'model3', 'model4', 'model5', 'model6', 'model7', 'model8', 'model9']\n",
      "remaining 17\n",
      "remaining models ['model0', 'model1', 'model10', 'model12', 'model13', 'model14', 'model15', 'model16', 'model17', 'model2', 'model3', 'model4', 'model5', 'model6', 'model7', 'model8', 'model9']\n",
      "remaining 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  3.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.89it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.90it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.90it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.90it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.90it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.89it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.90it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.90it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.89it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.89it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.90it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.89it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.90it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.83it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.89it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.73it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.84it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.86it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.86it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected models: ['model11', 'model8']\n",
      "Current MAE: 5.264071739196778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  3.89it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.89it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remaining ['model0', 'model1', 'model10', 'model12', 'model13', 'model14', 'model15', 'model16', 'model17', 'model2', 'model3', 'model4', 'model5', 'model6', 'model7', 'model9']\n",
      "remaining 16\n",
      "remaining models ['model0', 'model1', 'model10', 'model12', 'model13', 'model14', 'model15', 'model16', 'model17', 'model2', 'model3', 'model4', 'model5', 'model6', 'model7', 'model9']\n",
      "remaining 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  3.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.89it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.86it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.86it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.89it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.86it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.90it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.86it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.86it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.90it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.89it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.90it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.89it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.86it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.86it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.86it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.86it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.89it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.85it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.86it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.89it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.86it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.86it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.89it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remaining ['model0', 'model1', 'model10', 'model12', 'model13', 'model14', 'model15', 'model16', 'model17', 'model2', 'model3', 'model4', 'model5', 'model6', 'model7', 'model9']\n",
      "remaining 16\n",
      "remaining models ['model0', 'model1', 'model10', 'model12', 'model13', 'model14', 'model15', 'model16', 'model17', 'model2', 'model3', 'model4', 'model5', 'model6', 'model7', 'model9']\n",
      "remaining 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  3.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.86it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.90it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.90it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.90it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.90it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.90it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.90it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final selected models: ['model11', 'model8']\n",
      "Best MAE: 5.264071739196778\n",
      "Selected models for non thermophilic (class 0): ['model8']\n",
      "Best MAE non thermo: 6.785047042846678\n",
      "Selected models for thermophilic (class 1): ['model11', 'model8']\n",
      "Best MAE thermo: 5.264071739196778\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from analysis.ensemble import ClassificationBasedEnsemble\n",
    "print('*** ClassificationBasedEnsemble ***')\n",
    "models_non_thermo, best_mae_non_thermo, models_thermo, best_mae_thermo = ClassificationBasedEnsemble(regression_models=models,seq=X_val[:10], Tm=y_val[:10],classifier_model=classifier).ensemble()\n",
    "print('')\n",
    "print('')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "temBERTure_datavis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
